{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcGt-u2sU45a",
        "outputId": "07738d8a-f3e3-4f88-b989-2aeb25fd4d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "b-TlGAzhVHQU",
        "outputId": "e9a1146a-9f35-4c97-d0eb-3381397e4c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.2.1\n",
            "    Uninstalling keras-3.2.1:\n",
            "      Successfully uninstalled keras-3.2.1\n",
            "Successfully installed keras-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              },
              "id": "42f201eb501d47f68ff66d3f97147003"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN, GRU, LSTM, Bidirectional, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
        "df = pd.read_csv(file_path, delimiter='\\t')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_L0aqpDGBwi",
        "outputId": "2e4ed93d-6ece-4144-efc1-3bc7912a9275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet Class\n",
            "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
            "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
            "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
            "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
            "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tweet'] = df['Tweet'].str.lower()\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_jyuS2-GJJq",
        "outputId": "a5046920-e2b1-43e5-8d12-7e2cfd393092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet Class\n",
            "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
            "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
            "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
            "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
            "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Tweet']\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "AU_qPWC-KO7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary = np.where(y == 'P', 1, 0)"
      ],
      "metadata": {
        "id": "t8fk1tqsKQ1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if np.any((y_binary != 0) & (y_binary != 1)):\n",
        "    raise ValueError(\"Labels contain mixed or unknown targets.\")"
      ],
      "metadata": {
        "id": "ZUSOFjT_KSJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_labels = np.isnan(y_binary)\n",
        "if np.any(missing_labels):\n",
        "    raise ValueError(\"Missing values found in labels.\")"
      ],
      "metadata": {
        "id": "L0eTVu79KURB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary = np.expand_dims(y_binary, axis=-1)"
      ],
      "metadata": {
        "id": "tOhL0gejKVo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "max_sequence_length = 100\n",
        "X = pad_sequences(X, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "ymxnwHDNKW_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "xOI9hvSTKYrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_type, num_layers, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_sequence_length))\n",
        "    if model_type == 'RNN':\n",
        "        for _ in range(num_layers):\n",
        "            model.add(SimpleRNN(64, return_sequences=True))\n",
        "    elif model_type == 'GRU':\n",
        "        for _ in range(num_layers):\n",
        "            model.add(GRU(64, return_sequences=True))\n",
        "    elif model_type == 'LSTM':\n",
        "        for _ in range(num_layers):\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "    elif model_type == 'BiLSTM':\n",
        "        for _ in range(num_layers):\n",
        "            model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "k_VyCgy2Kcwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "num_layers_options = [2, 3]\n",
        "dropout_rate_options = [0.3, 0.7]"
      ],
      "metadata": {
        "id": "B97sk9-YKivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_type in ['RNN', 'GRU', 'LSTM', 'BiLSTM']:\n",
        "    for num_layers in num_layers_options:\n",
        "        for dropout_rate in dropout_rate_options:\n",
        "            model = create_model(model_type, num_layers, dropout_rate)\n",
        "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "            model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)\n",
        "            y_pred_prob = model.predict(X_test)\n",
        "            y_pred_mean = np.mean(y_pred_prob, axis=1)\n",
        "            y_pred = (y_pred_mean > 0.5).astype(int)\n",
        "            if y_test.shape != y_pred.shape:\n",
        "                raise ValueError(\"Shapes of y_test and y_pred do not match.\")\n",
        "            if np.isnan(y_test).any():\n",
        "                raise ValueError(\"Missing values found in y_test.\")\n",
        "            if y_test.shape != y_pred.shape:\n",
        "                raise ValueError(\"Shapes of y_test and y_pred do not match.\")\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision = precision_score(y_test, y_pred)\n",
        "            recall = recall_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            results.append({\n",
        "                'Model': model_type,\n",
        "                'Num Layers': num_layers,\n",
        "                'Dropout Rate': dropout_rate,\n",
        "                'Accuracy': accuracy,\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'F1-score': f1\n",
        "            })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTfbHLpkKnX8",
        "outputId": "6c15f9aa-d535-4409-d8b9-17f9f8a86bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 1s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 22ms/step\n",
            "8/8 [==============================] - 1s 47ms/step\n",
            "8/8 [==============================] - 1s 29ms/step\n",
            "8/8 [==============================] - 2s 67ms/step\n",
            "8/8 [==============================] - 2s 92ms/step\n",
            "8/8 [==============================] - 1s 40ms/step\n",
            "8/8 [==============================] - 1s 38ms/step\n",
            "8/8 [==============================] - 2s 48ms/step\n",
            "8/8 [==============================] - 2s 55ms/step\n",
            "8/8 [==============================] - 3s 66ms/step\n",
            "8/8 [==============================] - 2s 63ms/step\n",
            "8/8 [==============================] - 3s 101ms/step\n",
            "8/8 [==============================] - 4s 155ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXfnu6PZvKXR",
        "outputId": "97a13efd-f320-4fc2-f179-5cadcd03a768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Model  Num Layers  Dropout Rate  Accuracy  Precision    Recall  F1-score\n",
            "0      RNN           2           0.3     0.512   1.000000  0.039370  0.075758\n",
            "1      RNN           2           0.7     0.552   0.532751  0.960630  0.685393\n",
            "2      RNN           3           0.3     0.492   0.000000  0.000000  0.000000\n",
            "3      RNN           3           0.7     0.500   1.000000  0.015748  0.031008\n",
            "4      GRU           2           0.3     0.512   0.510288  0.976378  0.670270\n",
            "5      GRU           2           0.7     0.616   0.618321  0.637795  0.627907\n",
            "6      GRU           3           0.3     0.596   0.569149  0.842520  0.679365\n",
            "7      GRU           3           0.7     0.580   0.677419  0.330709  0.444444\n",
            "8     LSTM           2           0.3     0.572   0.621951  0.401575  0.488038\n",
            "9     LSTM           2           0.7     0.564   0.673077  0.275591  0.391061\n",
            "10    LSTM           3           0.3     0.512   0.608696  0.110236  0.186667\n",
            "11    LSTM           3           0.7     0.556   0.766667  0.181102  0.292994\n",
            "12  BiLSTM           2           0.3     0.596   0.610169  0.566929  0.587755\n",
            "13  BiLSTM           2           0.7     0.608   0.601399  0.677165  0.637037\n",
            "14  BiLSTM           3           0.3     0.600   0.617391  0.559055  0.586777\n",
            "15  BiLSTM           3           0.7     0.568   0.630137  0.362205  0.460000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION-2**"
      ],
      "metadata": {
        "id": "Ek1TXtkVLM0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4027H-KrrK80",
        "scrolled": true,
        "outputId": "6853935f-9083-4c10-bd52-8061dee0e919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0SL5oYwvHbo",
        "outputId": "56092a19-e067-42ff-e8d4-8ef0ec0aa1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.2.1\n",
            "    Uninstalling keras-3.2.1:\n",
            "      Successfully uninstalled keras-3.2.1\n",
            "Successfully installed keras-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "rEjODldaPZ6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgK8tnGJZSa1",
        "outputId": "dd575676-4f07-454c-aab1-66d114a22409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "VL3wmAuwVpMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model_path = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin'\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=True, limit=20000)"
      ],
      "metadata": {
        "id": "emvDPSF-Z5-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
        "df = pd.read_csv(file_path, delimiter='\\t')"
      ],
      "metadata": {
        "id": "eDReoDKXZ7X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Tweet']\n",
        "y = df['Class']\n",
        "y_binary = np.where(y == 'P', 1, 0)"
      ],
      "metadata": {
        "id": "BGkImjgZZ8u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "DsOizaw3Z-Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "q3UZL9iOaABt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model:\n",
        "        embedding_matrix[i] = word2vec_model[word]"
      ],
      "metadata": {
        "id": "5tUfDZUXaEFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, weights=[embedding_matrix],\n",
        "                    input_length=max_sequence_length, trainable=False))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "VJna-g_8aFDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
        "y_pred_prob = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4iG29d7aJWP",
        "outputId": "dcd5b9e0-b49b-4482-a0f5-c07cae85dc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 12s 400ms/step - loss: 0.6928 - accuracy: 0.5253\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 5s 437ms/step - loss: 0.6919 - accuracy: 0.5293\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 3s 200ms/step - loss: 0.6914 - accuracy: 0.5280\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 2s 196ms/step - loss: 0.6930 - accuracy: 0.5307\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 2s 199ms/step - loss: 0.6922 - accuracy: 0.5240\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 2s 196ms/step - loss: 0.6922 - accuracy: 0.5293\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 4s 309ms/step - loss: 0.6904 - accuracy: 0.5267\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 3s 237ms/step - loss: 0.6919 - accuracy: 0.5253\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 2s 196ms/step - loss: 0.6933 - accuracy: 0.5293\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 2s 195ms/step - loss: 0.6926 - accuracy: 0.5187\n",
            "8/8 [==============================] - 1s 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (y_pred_prob > threshold).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GqSaX99aK9x",
        "outputId": "d817aa91-621c-4f00-8094-69479faad8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for threshold in np.arange(0.1, 0.5, 0.1):\n",
        "    y_pred = (y_pred_prob > threshold).astype(int)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results.append({'Threshold': threshold, 'Precision': precision, 'Recall': recall, 'F1-score': f1})"
      ],
      "metadata": {
        "id": "rhw5Vd5BaM3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqGH4PhMnW2o",
        "outputId": "5c1157cf-3bbf-46d3-91ac-bfedafb0bb03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.492\n",
            "Precision: 0.508\n",
            "Recall: 1.0\n",
            "F1-score: 0.6737400530503979\n",
            "   Threshold  Precision  Recall  F1-score\n",
            "0        0.1      0.508     1.0   0.67374\n",
            "1        0.2      0.508     1.0   0.67374\n",
            "2        0.3      0.508     1.0   0.67374\n",
            "3        0.4      0.508     1.0   0.67374\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n"
      ],
      "metadata": {
        "id": "6f63p1t-P-gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings_path = '/content/drive/MyDrive/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_embeddings_path)"
      ],
      "metadata": {
        "id": "_W2ED4IDQATV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
        "df = pd.read_csv(file_path, delimiter='\\t')"
      ],
      "metadata": {
        "id": "h_pIGIG8QCJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Tweet']\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "qi49IlDRQEl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary = np.where(y == 'P', 1, 0)"
      ],
      "metadata": {
        "id": "oPdaG0avQG7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "fzW1tztzQImM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "VZEX1_F2QKjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "n12NDJF6QOsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "fgElcQfbQQ0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=300, weights=[embedding_matrix], input_length=max_sequence_length, trainable=False))\n",
        "model.add(LSTM(64, return_sequences=True))  # First LSTM layer\n",
        "model.add(Dropout(0.7))\n",
        "model.add(LSTM(64))  # Second LSTM layer\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "-u_50VTjQT-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rkJ7Y7ZBQW3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qusVKAhuQZWN",
        "outputId": "644f59f9-ac0e-4467-f402-fe4856b87620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 8s 271ms/step - loss: 0.6936 - accuracy: 0.5200\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 3s 284ms/step - loss: 0.6904 - accuracy: 0.5480\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 2s 198ms/step - loss: 0.6915 - accuracy: 0.5307\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 2s 195ms/step - loss: 0.6889 - accuracy: 0.5387\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 2s 198ms/step - loss: 0.6898 - accuracy: 0.5320\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 3s 238ms/step - loss: 0.6848 - accuracy: 0.5493\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 4s 344ms/step - loss: 0.6814 - accuracy: 0.5600\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 2s 194ms/step - loss: 0.6831 - accuracy: 0.5640\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 2s 197ms/step - loss: 0.6743 - accuracy: 0.5560\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 2s 198ms/step - loss: 0.6770 - accuracy: 0.5693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e1f05fdbd60>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKROCHxFQbeG",
        "outputId": "a8972c65-7804-418b-e99b-3f5820fe62c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 97ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (y_pred_prob > threshold).astype(int)"
      ],
      "metadata": {
        "id": "XSCyQTQHQdnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "kKYLVCPKQfVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for threshold in np.arange(0.1, 0.6, 0.1):\n",
        "    y_pred = (y_pred_prob > threshold).astype(int)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results.append({'Threshold': threshold, 'Precision': precision, 'Recall': recall, 'F1-score': f1})"
      ],
      "metadata": {
        "id": "3vEhuCtqQf_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx5YcwCqsear",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687df077-c1db-4999-9022-b8fb8052ac1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics:\n",
            "Accuracy: 0.496\n",
            "Precision: 0.5454545454545454\n",
            "Recall: 0.047244094488188976\n",
            "F1-score: 0.08695652173913043\n",
            "   Threshold  Precision    Recall  F1-score\n",
            "0        0.1   0.508000  1.000000  0.673740\n",
            "1        0.2   0.508000  1.000000  0.673740\n",
            "2        0.3   0.508000  1.000000  0.673740\n",
            "3        0.4   0.508696  0.921260  0.655462\n",
            "4        0.5   0.545455  0.047244  0.086957\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluation metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from gensim.models import KeyedVectors\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Qp-Mx19tYXEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR10lApnrwnU"
      },
      "outputs": [],
      "source": [
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec', binary=False, limit=20000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
        "df = pd.read_csv(file_path, delimiter='\\t')"
      ],
      "metadata": {
        "id": "zcy9cBpGWzTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Tweet']\n",
        "y = df['Class']\n",
        "y_binary = np.where(y == 'P', 1, 0)"
      ],
      "metadata": {
        "id": "MerFRC5fW0pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "udM4jfDoW15I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[i] = fasttext_model[word]"
      ],
      "metadata": {
        "id": "6QQPjwPuW3r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=300, weights=[embedding_matrix], input_length=max_sequence_length, trainable=False))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "axVJ-nshW5Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1WVvr3pW6m_",
        "outputId": "9c8d2905-7e33-4eaf-adb1-4d9a221e7e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 8s 195ms/step - loss: 0.6925 - accuracy: 0.5293\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 4s 314ms/step - loss: 0.6916 - accuracy: 0.5307\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 3s 227ms/step - loss: 0.6917 - accuracy: 0.5293\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 2s 193ms/step - loss: 0.6931 - accuracy: 0.5293\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 2s 193ms/step - loss: 0.6912 - accuracy: 0.5187\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 2s 193ms/step - loss: 0.6916 - accuracy: 0.5133\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 3s 263ms/step - loss: 0.6927 - accuracy: 0.5160\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 3s 274ms/step - loss: 0.6931 - accuracy: 0.5280\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 2s 191ms/step - loss: 0.6926 - accuracy: 0.5187\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 2s 194ms/step - loss: 0.6911 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e1f05fa8040>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DtthRfdW74s",
        "outputId": "30022bd7-8445-4adb-f646-3ab3d2ecb2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 53ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (y_pred_prob > threshold).astype(int)"
      ],
      "metadata": {
        "id": "3JE3ZWXAW9Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "QQyXKB6eW-3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbpJAD7nXAOw",
        "outputId": "7afdcf15-a47c-406e-e032-76775255ec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics:\n",
            "Accuracy: 0.496\n",
            "Precision: 1.0\n",
            "Recall: 0.007874015748031496\n",
            "F1-score: 0.015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for threshold in np.arange(0.1, 0.6, 0.1):\n",
        "    y_pred = (y_pred_prob > threshold).astype(int)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results.append({'Threshold': threshold, 'Precision': precision, 'Recall': recall, 'F1-score': f1})"
      ],
      "metadata": {
        "id": "c2vH-I4AXCkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LpYeNqxuAcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4990d6e0-5125-4c21-9bfc-e3e5c66bce31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Threshold  Precision    Recall  F1-score\n",
            "0        0.1      0.508  1.000000  0.673740\n",
            "1        0.2      0.508  1.000000  0.673740\n",
            "2        0.3      0.508  1.000000  0.673740\n",
            "3        0.4      0.508  1.000000  0.673740\n",
            "4        0.5      1.000  0.007874  0.015625\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-tQ2gPyuDNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61b1c82-4b02-4508-bc14-fef94f38346e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.10/dist-packages (2.10.1)\n",
            "Requirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.12.1)\n",
            "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.13.1)\n",
            "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.1.6)\n",
            "Requirement already satisfied: fairscale==0.4.6 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.4.6)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.1)\n",
            "Requirement already satisfied: spacy<3.4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.25.2)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.6.2.2)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.66.2)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.11.4)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (7.4.4)\n",
            "Requirement already satisfied: transformers<4.21,>=4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.20.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.1.99)\n",
            "Requirement already satisfied: filelock<3.8,>=3.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.7.1)\n",
            "Requirement already satisfied: lmdb>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (10.1.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.12.21)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.10.1)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.3.8)\n",
            "Requirement already satisfied: base58>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.1.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.1.1)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.4.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.20.3)\n",
            "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (5.7.1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.20.0)\n",
            "Requirement already satisfied: rich<13.0,>=12.1 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (12.6.0)\n",
            "Requirement already satisfied: boto3<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.34.87)\n",
            "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (24.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (2023.12.25)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.4.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.43)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.0.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.45.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.3)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.87 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.34.87)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.10.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.11)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.7.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp) (0.1.1)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.87->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "#ELMO\n",
        "!pip install allennlp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUZLRDC9vHbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88672da9-4fa4-4cbd-9d04-e7b69cf1c4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: allennlp\n",
            "Version: 2.10.1\n",
            "Summary: An open-source NLP research library, built on PyTorch.\n",
            "Home-page: https://github.com/allenai/allennlp\n",
            "Author: Allen Institute for Artificial Intelligence\n",
            "Author-email: allennlp@allenai.org\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: base58, cached-path, dill, fairscale, filelock, h5py, huggingface-hub, jsonnet, lmdb, more-itertools, nltk, numpy, protobuf, pytest, requests, sacremoses, scikit-learn, scipy, sentencepiece, spacy, tensorboardX, termcolor, torch, torchvision, tqdm, traitlets, transformers, typer, wandb\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show allennlp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten"
      ],
      "metadata": {
        "id": "BtdSNGsWjBZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
        "df = pd.read_csv(file_path, delimiter='\\t')"
      ],
      "metadata": {
        "id": "K7jwzzDLjEWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Tweet']\n",
        "y = df['Class']\n",
        "y_binary = np.where(y == 'P', 1, 0)"
      ],
      "metadata": {
        "id": "dberCLIzjGbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "PsowHERpjIQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)"
      ],
      "metadata": {
        "id": "M4-E75RfjN7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_elmo_embeddings(sentences, max_length=50):\n",
        "    character_ids = batch_to_ids([sentence.split() for sentence in sentences])\n",
        "    embeddings = elmo(character_ids)['elmo_representations'][0].detach().numpy()\n",
        "    padded_embeddings = np.zeros((len(sentences), max_length, embeddings.shape[2]))\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        if embedding.shape[0] < max_length:\n",
        "            padded_embeddings[i, :embedding.shape[0], :] = embedding\n",
        "        else:\n",
        "            padded_embeddings[i, :, :] = embedding[:max_length, :]\n",
        "    return padded_embeddings"
      ],
      "metadata": {
        "id": "pTt5H7w3jQ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_elmo = get_elmo_embeddings(X_train)\n",
        "X_test_elmo = get_elmo_embeddings(X_test)"
      ],
      "metadata": {
        "id": "hq7oQpYEjSm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_elmo.shape[1], X_train_elmo.shape[2])))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())  # Add Flatten layer to convert 3D output to 2D\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_ioKuD0XjU4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uSP1N7f5jXJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSzjvDrDyGyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_elmo, y_train, epochs=10, batch_size=64, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB5jXgtqjY0H",
        "outputId": "c8db550c-c262-417f-8259-af72c152f4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 2s 39ms/step - loss: 0.7460 - accuracy: 0.4907\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.6931 - accuracy: 0.5547\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6774 - accuracy: 0.5787\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6658 - accuracy: 0.6080\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6507 - accuracy: 0.6333\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6323 - accuracy: 0.6627\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6282 - accuracy: 0.6640\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6060 - accuracy: 0.6680\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.5921 - accuracy: 0.7053\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5808 - accuracy: 0.6893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c05f93e89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_elmo, y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM6k64tWjfle",
        "outputId": "3219c993-cac4-4591-9c19-cd40a9571cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5239999890327454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test_elmo)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpERFMlBjlSZ",
        "outputId": "6b07781c-0e15-4b8c-91b2-df292d20bc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "gx5RnxwyjnOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMPb4RA7uXUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa01eead-b6dc-40c2-8fc1-3f86ce7f2118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.532258064516129\n",
            "Recall: 0.5196850393700787\n",
            "F1-score: 0.5258964143426295\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}